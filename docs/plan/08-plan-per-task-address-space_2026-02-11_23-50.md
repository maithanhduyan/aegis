# Káº¿ hoáº¡ch Phase H â€” Per-Task Address Space

> **Tráº¡ng thÃ¡i: âœ… HOÃ€N THÃ€NH** â€” Má»—i task cÃ³ báº£ng trang riÃªng (per-task page table). Task A khÃ´ng thá»ƒ Ä‘á»c/ghi bá»™ nhá»› cá»§a Task B, ká»ƒ cáº£ cÃ¹ng cháº¡y á»Ÿ EL0. TTBR0_EL1 Ä‘Æ°á»£c swap khi context switch + ASID tag TLB. ÄÃ¢y lÃ  lá»›p cÃ¡ch ly bá»™ nhá»› báº¯t buá»™c cho safety-critical (DO-178C Â§5.3.1 â€” memory partitioning, ISO 26262 Part 6 Â§7.4.6 â€” freedom from interference).

---

## Táº¡i sao Phase H?

### Lá»— há»•ng hiá»‡n táº¡i: "Ai cÅ©ng nhÃ¬n tháº¥y bá»™ nhá»› cá»§a nhau"

Phase G Ä‘Ã£ kiá»ƒm soÃ¡t **syscall** â€” má»—i task chá»‰ gá»i Ä‘Æ°á»£c syscall mÃ  nÃ³ cÃ³ quyá»n. NhÆ°ng váº«n cÃ²n má»™t lá»— há»•ng lá»›n:

**Táº¥t cáº£ task chia chung má»™t báº£ng trang (page table).** Ba vÃ¹ng user stack (`__user_stacks_start` â†’ `__user_stacks_end`, 3Ã—4KB) Ä‘á»u dÃ¹ng descriptor `AP_RW_EL0` â€” nghÄ©a lÃ  **báº¥t ká»³ task EL0 nÃ o cÅ©ng Ä‘á»c/ghi Ä‘Æ°á»£c stack cá»§a task khÃ¡c**.

VÃ­ dá»¥ thá»±c táº¿:
- Task A (PING) Ä‘ang lÆ°u dá»¯ liá»‡u nháº¡y cáº£m trÃªn stack â†’ Task B cÃ³ thá»ƒ Ä‘á»c trá»±c tiáº¿p
- Task B bá»‹ lá»—i ghi trÃ n â†’ cÃ³ thá»ƒ ghi Ä‘Ã¨ stack cá»§a Task A â†’ Task A crash theo
- Hacker chiáº¿m Task idle â†’ quÃ©t toÃ n bá»™ 12KB user stack tÃ¬m dá»¯ liá»‡u

Capability **khÃ´ng cháº·n Ä‘Æ°á»£c** Ä‘iá»u nÃ y â€” capability kiá»ƒm soÃ¡t syscall, khÃ´ng kiá»ƒm soÃ¡t truy cáº­p bá»™ nhá»› trá»±c tiáº¿p (load/store instruction).

### Giáº£i phÃ¡p: Per-Task Page Table + TTBR0 Swap

Má»—i task cÃ³ báº£ng trang riÃªng. Trong báº£ng trang cá»§a Task A:
- Stack cá»§a Task A: `AP_RW_EL0` (Ä‘á»c/ghi Ä‘Æ°á»£c) âœ…
- Stack cá»§a Task B: **khÃ´ng cÃ³ mapping** hoáº·c `AP_RW_EL1` (EL0 fault) âŒ
- Stack cá»§a Task C: **khÃ´ng cÃ³ mapping** hoáº·c `AP_RW_EL1` (EL0 fault) âŒ
- Kernel code/data: giá»¯ nguyÃªn mapping (EL1 only hoáº·c shared code)

Khi context switch: kernel ghi TTBR0_EL1 = báº£ng trang cá»§a task má»›i â†’ CPU dÃ¹ng báº£ng trang má»›i â†’ task má»›i chá»‰ tháº¥y bá»™ nhá»› cá»§a chÃ­nh nÃ³.

---

## PhÃ¢n tÃ­ch hiá»‡n tráº¡ng

### Báº£ng trang hiá»‡n táº¡i: 1 bá»™ duy nháº¥t, 4 pages

```
L1 (page 0, 512 entries)
â”œâ”€â”€ [0] â†’ L2_device (page 1) â€” 0x0000_0000..0x3FFF_FFFF
â”‚         â”œâ”€â”€ [64..72] â†’ Device MMIO 2MB blocks (GIC, UART)
â”‚         â””â”€â”€ rest â†’ invalid
â”‚
â””â”€â”€ [1] â†’ L2_ram (page 2) â€” 0x4000_0000..0x7FFF_FFFF
          â”œâ”€â”€ [0] â†’ L3_kernel (page 3) â€” 0x4000_0000..0x401F_FFFF (first 2MB)
          â”‚         â”œâ”€â”€ text pages:  AP_RO_EL0 (exec by both EL0+EL1)
          â”‚         â”œâ”€â”€ rodata:     AP_RO_EL0, XN
          â”‚         â”œâ”€â”€ data/bss:   AP_RW_EL1, XN (EL0 no access)
          â”‚         â”œâ”€â”€ page_tables: AP_RW_EL1, XN
          â”‚         â”œâ”€â”€ task_stacks: AP_RW_EL1, XN (kernel stacks)
          â”‚         â”œâ”€â”€ user_stacks: AP_RW_EL0, XN â† ğŸ”´ Táº¤T Cáº¢ EL0 Äá»ŒC/GHI ÄÆ¯á»¢C
          â”‚         â”œâ”€â”€ guard page:  invalid
          â”‚         â””â”€â”€ boot stack:  AP_RW_EL1, XN
          â”‚
          â””â”€â”€ [1..63] â†’ RAM 2MB blocks, AP_RW_EL1 (EL0 no access)
```

**Váº¥n Ä‘á» cá»‘t lÃµi:** Chá»‰ cÃ³ 1 báº£ng L3, user stacks dÃ¹ng `AP_RW_EL0` chung â†’ má»i EL0 task Ä‘á»u truy cáº­p Ä‘Æ°á»£c.

### TTBR0/TTBR1 hiá»‡n táº¡i

- **TTBR0_EL1** = `__page_tables_start` (L1 base) â€” duy nháº¥t, khÃ´ng Ä‘á»•i
- **TTBR1_EL1** = **disabled** (`EPD1=1` trong TCR_EL1)
- **KhÃ´ng dÃ¹ng ASID** â€” TTBR0 bits [63:48] = 0

### TCB hiá»‡n táº¡i (sau Phase G)

```
Tcb {
    context:        TrapFrame,  // 288B â€” ABI-locked, offset 0
    state:          TaskState,  // 1B
    id:             u16,        // 2B
    stack_top:      u64,        // 8B â€” SP_EL1 (kernel stack per task)
    entry_point:    u64,        // 8B â€” restart point
    user_stack_top: u64,        // 8B â€” SP_EL0
    fault_tick:     u64,        // 8B â€” tick khi Faulted
    caps:           CapBits,    // 8B â€” capability bitmask
}
```

### Context switch hiá»‡n táº¡i

```
Timer IRQ (EL0 â†’ EL1):
1. SAVE_CONTEXT_LOWER macro:
   - Stash x9 â†’ TPIDR_EL1
   - Load SP = __stack_end (shared kernel boot stack, 16KB)
   - Save x0â€“x30, SP_EL0, ELR_EL1, SPSR_EL1 vÃ o TrapFrame trÃªn stack
   - x0 = &TrapFrame

2. handle_timer_irq(frame) â†’ schedule():
   - save_context(): copy TrapFrame vÃ o TCBS[CURRENT].context
   - Chá»n next Ready task (round-robin)
   - restore_context(): copy TCBS[next].context ra TrapFrame

3. RESTORE_CONTEXT_LOWER macro:
   - Load SP_EL0, ELR_EL1, SPSR_EL1 tá»« TrapFrame
   - Load x0â€“x30
   - eret â†’ EL0

âš ï¸ KHÃ”NG swap TTBR0 á»Ÿ báº¥t ká»³ bÆ°á»›c nÃ o.
```

### User stack addresses

| Task | Stack Base | Stack Top (SP_EL0) |
|---|---|---|
| 0 | `__user_stacks_start` | `__user_stacks_start + 0x1000` |
| 1 | `__user_stacks_start + 0x1000` | `__user_stacks_start + 0x2000` |
| 2 | `__user_stacks_start + 0x2000` | `__user_stacks_start + 0x3000` |

Táº¥t cáº£ náº±m trong 3 page liÃªn tiáº¿p trong vÃ¹ng L3_kernel.

---

## Thiáº¿t káº¿ Phase H

### Chiáº¿n lÆ°á»£c: TTBR0-only, swap per-task L3

Giá»¯ kiáº¿n trÃºc TTBR0-only (khÃ´ng báº­t TTBR1), nhÆ°ng má»—i task cÃ³ **bá»™ page table riÃªng** vá»›i mapping user stack khÃ¡c nhau. Cá»¥ thá»ƒ:

| Table | Chia sáº»? | LÃ½ do |
|---|---|---|
| L1 | **Per-task** (3 báº£n) | TTBR0 trá» vÃ o Ä‘Ã¢y, cáº§n riÃªng |
| L2_device | **Chia sáº»** (1 báº£n) | Device MMIO giá»‘ng nhau cho má»i task |
| L2_ram | **Per-task** (3 báº£n) | Entry [0] trá» vÃ o L3 riÃªng |
| L3 | **Per-task** (3 báº£n) | User stack mapping khÃ¡c nhau |

Thay vÃ¬ clone toÃ n bá»™ L3 512 entries, chá»‰ cáº§n **thay Ä‘á»•i 3 entry** (3 user stack pages):
- Task 0 L3: user stack page 0 = `AP_RW_EL0`, page 1,2 = `AP_RW_EL1` (hoáº·c invalid)
- Task 1 L3: user stack page 1 = `AP_RW_EL0`, page 0,2 = `AP_RW_EL1`
- Task 2 L3: user stack page 2 = `AP_RW_EL0`, page 0,1 = `AP_RW_EL1`

Má»i entry khÃ¡c (text, rodata, data, bss, kernel stacks) **giá»‘ng há»‡t nhau**.

### Báº£ng trang má»›i: 13 pages

| Page | Má»¥c Ä‘Ã­ch | Ná»™i dung |
|---|---|---|
| 0 | L2_device (chia sáº») | Giá»‘ng cÅ© |
| 1 | L1 cho Task 0 | [0] â†’ L2_device, [1] â†’ L2_ram_task0 |
| 2 | L1 cho Task 1 | [0] â†’ L2_device, [1] â†’ L2_ram_task1 |
| 3 | L1 cho Task 2 | [0] â†’ L2_device, [1] â†’ L2_ram_task2 |
| 4 | L2_ram cho Task 0 | [0] â†’ L3_task0, [1..63] â†’ RAM blocks |
| 5 | L2_ram cho Task 1 | [0] â†’ L3_task1, [1..63] â†’ RAM blocks |
| 6 | L2_ram cho Task 2 | [0] â†’ L3_task2, [1..63] â†’ RAM blocks |
| 7 | L3 cho Task 0 | user_stack_0 = RW_EL0, stack 1,2 = RW_EL1 |
| 8 | L3 cho Task 1 | user_stack_1 = RW_EL0, stack 0,2 = RW_EL1 |
| 9 | L3 cho Task 2 | user_stack_2 = RW_EL0, stack 0,1 = RW_EL1 |
| 10 | L1 kernel (boot) | DÃ¹ng cho boot + exception handler trÆ°á»›c khi task cháº¡y |
| 11 | L2_ram kernel | Giá»‘ng cÅ©, táº¥t cáº£ user stacks = AP_RW_EL1 |
| 12 | L3 kernel | Giá»‘ng cÅ© nhÆ°ng user stacks = AP_RW_EL1 (kernel access only) |

**Tá»•ng: 13 pages = 52 KiB** (thÃªm 36 KiB so vá»›i hiá»‡n táº¡i).

> **LÆ°u Ã½:** Kernel boot page table (pages 10-12) dÃ¹ng trong exception handler context â€” khi handler cháº¡y, TTBR0 trá» tá»›i page table cá»§a task hiá»‡n táº¡i, nhÆ°ng kernel code cÃ³ AP_RW_EL1 nÃªn váº«n truy cáº­p Ä‘Æ°á»£c má»i thá»©. **KhÃ´ng cáº§n** swap TTBR0 khi vÃ o exception handler vÃ¬ kernel cháº¡y á»Ÿ EL1 â€” AP_RW_EL1 entries trong per-task page table Ä‘Ã£ cáº¥p quyá»n cho kernel.

### ASID (Address Space Identifier)

- TTBR0_EL1 bits [63:48] = **ASID** â€” tag cho TLB entries
- Má»—i task cÃ³ ASID riÃªng: Task 0 = ASID 1, Task 1 = ASID 2, Task 2 = ASID 3
- Khi swap TTBR0: TLB entries tagged ASID cÅ© **khÃ´ng cáº§n flush** â€” CPU tá»± bá» qua
- Chá»‰ cáº§n `isb` sau `msr ttbr0_el1` Ä‘á»ƒ Ä‘áº£m báº£o pipeline consistency
- Giáº£m **chi phÃ­ TLB miss** Ä‘Ã¡ng ká»ƒ so vá»›i `tlbi vmalle1` má»—i láº§n switch

**TCR_EL1 cáº§n báº­t A1=0 (ASID tá»« TTBR0)** â€” hiá»‡n táº¡i A1 bit chÆ°a set â†’ máº·c Ä‘á»‹nh = 0 â†’ OK.

### TCB thÃªm field `ttbr0`

```
Tcb {
    ...existing fields...
    caps:  CapBits,    // 8B
    ttbr0: u64,        // 8B â€” TTBR0 value = (ASID << 48) | page_table_phys_base
}
```

### Context switch má»›i

```
schedule():
    save_context()          // nhÆ° cÅ©
    pick next task          // nhÆ° cÅ©
    restore_context()       // nhÆ° cÅ©

    // â”€â”€â”€ Má»šI: swap address space â”€â”€â”€
    let new_ttbr0 = TCBS[next].ttbr0;
    msr ttbr0_el1, new_ttbr0
    isb
```

Äáº·t sau `restore_context()`, trÆ°á»›c khi `eret`. Hoáº·c cÃ³ thá»ƒ Ä‘áº·t trong `restore_context()` luÃ´n.

### HÃ nh vi khi restart

`restart_task()` reset context nhÆ°ng **giá»¯ nguyÃªn `ttbr0`** â€” page table lÃ  chÃ­nh sÃ¡ch tÄ©nh, giá»‘ng nhÆ° `caps`. Task restart váº«n dÃ¹ng cÃ¹ng address space.

### áº¢nh hÆ°á»Ÿng Ä‘áº¿n `validate_write_pointer`

HÃ m `validate_write_pointer` hiá»‡n kiá»ƒm tra range `[0x4000_0000, 0x4800_0000)`. Vá»›i per-task page table:
- Range váº«n Ä‘Ãºng (identity mapping giá»¯ nguyÃªn cho kernel side)
- NhÆ°ng kernel ghi vÃ o user pointer qua **kernel's EL1 access** â†’ luÃ´n cÃ³ quyá»n ghi (AP_RW_EL1 entries trong per-task table váº«n accessible)
- **KhÃ´ng cáº§n thay Ä‘á»•i** `validate_write_pointer` â€” nÃ³ cháº¡y á»Ÿ EL1 context

### áº¢nh hÆ°á»Ÿng Ä‘áº¿n IPC

- IPC dÃ¹ng **register copy** (x0â€“x3 trong TrapFrame) â†’ khÃ´ng truy cáº­p user memory
- `copy_message()` copy giá»¯a `TCBS[].context.x[]` â†’ kernel BSS â†’ OK
- **KhÃ´ng áº£nh hÆ°á»Ÿng**

### áº¢nh hÆ°á»Ÿng Ä‘áº¿n Shared Code

- Táº¥t cáº£ `.text` lÃ  `SHARED_CODE_PAGE` (AP_RO_EL0) â†’ giá»‘ng nhau trong má»i per-task L3
- Task váº«n execute code á»Ÿ EL0 bÃ¬nh thÆ°á»ng
- **KhÃ´ng áº£nh hÆ°á»Ÿng**

---

## CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### H1 â€” Má»Ÿ rá»™ng page table storage + refactor `mmu::init()`

**Má»¥c tiÃªu:** Cáº¥p phÃ¡t Ä‘á»§ 13 pages cho page tables. Refactor `init()` Ä‘á»ƒ build per-task tables.

**Thay Ä‘á»•i:**

1. **Sá»­a `linker.ld`:**
   - Thay `.page_tables` size: `4 * 4096` â†’ `13 * 4096` (52 KiB)
   - Giá»¯ 4KB alignment

2. **Sá»­a `src/mmu.rs`:**
   - ThÃªm háº±ng sá»‘ `NUM_PAGE_TABLE_PAGES = 13`
   - ThÃªm háº±ng sá»‘ cho page index: `PT_L2_DEVICE = 0`, `PT_L1_TASK0 = 1`, ..., `PT_L3_KERNEL = 12`
   - Refactor `init()`:
     a. Build L2_device (page 0) â€” chia sáº», giá»‘ng cÅ©
     b. Build L3 cho má»—i task (pages 7,8,9): clone tá»« template, chá»‰ thay user stack AP bits
     c. Build L2_ram cho má»—i task (pages 4,5,6): entry[0] â†’ L3 riÃªng, entries[1..63] â†’ RAM blocks
     d. Build L1 cho má»—i task (pages 1,2,3): [0] â†’ L2_device, [1] â†’ L2_ram riÃªng
     e. Build kernel boot tables (pages 10,11,12): user stacks = AP_RW_EL1
   - ThÃªm hÃ m `pub fn page_table_base(task_id: usize) -> u64` â€” tráº£ physical address cá»§a L1 cho task Ä‘Ã³
   - ThÃªm hÃ m `pub fn ttbr0_for_task(task_id: usize, asid: u16) -> u64` â€” tráº£ `(asid << 48) | base`

3. **Sá»­a `src/boot.s`:**
   - TTBR0_EL1 ban Ä‘áº§u trá» vÃ o **kernel boot L1** (page 10) â€” khÃ´ng pháº£i per-task table
   - Thay `__page_tables_start` â†’ `__page_tables_start + 10 * 4096` (hoáº·c dÃ¹ng symbol má»›i)

**Checkpoint:** Build thÃ nh cÃ´ng. QEMU boot bÃ¬nh thÆ°á»ng â€” kernel váº«n dÃ¹ng kernel boot page table, chÆ°a swap. Táº¥t cáº£ test cÅ© pass.

---

### H2 â€” ThÃªm `ttbr0` vÃ o TCB + gÃ¡n trong `kernel_main`

**Má»¥c tiÃªu:** Má»—i task biáº¿t page table cá»§a mÃ¬nh. ChÆ°a swap.

**Thay Ä‘á»•i:**

1. **Sá»­a `src/sched.rs`:**
   - ThÃªm `pub ttbr0: u64` vÃ o `Tcb` (cuá»‘i struct, sau `caps`)
   - Cáº­p nháº­t `EMPTY_TCB`: `ttbr0: 0`

2. **Sá»­a `src/main.rs` â€” `kernel_main()`:**
   - Sau capability assignment, gÃ¡n `ttbr0` cho má»—i task:
     ```
     TCBS[0].ttbr0 = mmu::ttbr0_for_task(0, 1);  // ASID=1
     TCBS[1].ttbr0 = mmu::ttbr0_for_task(1, 2);  // ASID=2
     TCBS[2].ttbr0 = mmu::ttbr0_for_task(2, 3);  // ASID=3
     ```
   - ThÃªm UART: `"[AegisOS] per-task address spaces assigned\n"`

3. **Sá»­a `src/sched.rs` â€” `restart_task()`:**
   - XÃ¡c nháº­n `ttbr0` khÃ´ng bá»‹ reset (giá»‘ng `caps`)

**Checkpoint:** Build pass. QEMU boot hiá»ƒn thá»‹ message má»›i. ChÆ°a swap â†’ hÃ nh vi y há»‡t cÅ©.

---

### H3 â€” Swap TTBR0 trong context switch

**Má»¥c tiÃªu:** Má»—i khi chuyá»ƒn task, kernel load TTBR0 má»›i. **ÄÃ¢y lÃ  bÆ°á»›c critical.**

**Thay Ä‘á»•i:**

1. **Sá»­a `src/sched.rs` â€” `schedule()`:**
   - Sau `restore_context()`, trÆ°á»›c return:
     ```
     let new_ttbr0 = TCBS[CURRENT].ttbr0;
     unsafe {
         core::arch::asm!(
             "msr ttbr0_el1, {val}",
             "isb",
             val = in(reg) new_ttbr0,
             options(nomem, nostack)
         );
     }
     ```

2. **Sá»­a `src/sched.rs` â€” `bootstrap()`:**
   - TrÆ°á»›c `eret`, load TTBR0 cho task 0:
     ```
     msr ttbr0_el1, {ttbr0}
     isb
     ```

3. **Edge case: exception handler cháº¡y vá»›i per-task TTBR0**
   - Khi timer IRQ xáº£y ra á»Ÿ EL0, CPU chuyá»ƒn sang EL1 nhÆ°ng **TTBR0 váº«n lÃ  cá»§a task cÅ©**
   - **KhÃ´ng sao** vÃ¬: kernel code/data trong per-task table Ä‘á»u cÃ³ AP_RW_EL1 â†’ kernel Ä‘á»c/ghi Ä‘Æ°á»£c
   - `SAVE_CONTEXT_LOWER` load SP = `__stack_end` â†’ vÃ¹ng kernel stack, AP_RW_EL1 â†’ OK
   - `TCBS[]` náº±m trong `.bss` â†’ AP_RW_EL1 â†’ OK
   - Chá»‰ user stacks khÃ¡c â†’ nhÆ°ng handler khÃ´ng truy cáº­p user stack trá»±c tiáº¿p

4. **Edge case: `handle_write` truy cáº­p user pointer**
   - `SYS_WRITE` Ä‘á»c byte tá»« user pointer â†’ dÃ¹ng EL1 access â†’ AP_RW_EL1 cho vÃ¹ng text/rodata
   - User truyá»n pointer vÃ o `.text` (shared code, AP_RO_EL0) hoáº·c `.rodata` â†’ cáº£ hai Ä‘á»u mapped
   - **Náº¿u user truyá»n pointer vÃ o stack task khÃ¡c** â†’ trong per-task table, stack khÃ¡c = AP_RW_EL1 â†’ EL1 váº«n Ä‘á»c Ä‘Æ°á»£c â†’ `validate_write_pointer` chá»‰ check range, khÃ´ng check ownership
   - **Cáº§n xem xÃ©t:** cÃ³ nÃªn thÃªm check ownership vÃ o `validate_write_pointer`? â†’ Phase H3 chá»‰ swap TTBR0, ownership check Ä‘á»ƒ H4 hoáº·c tÆ°Æ¡ng lai.

**Checkpoint:** QEMU boot, PING/PONG hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng. Log thÃªm "per-task address spaces active" sau bootstrap. Má»—i task cháº¡y trong address space riÃªng.

---

### H4 â€” Kiá»ƒm chá»©ng cÃ¡ch ly trÃªn QEMU

**Má»¥c tiÃªu:** Chá»©ng minh task khÃ´ng Ä‘á»c Ä‘Æ°á»£c stack cá»§a task khÃ¡c.

**Thay Ä‘á»•i:**

1. **ThÃªm test scenario (gated by `#[cfg(feature = "test-isolation")]`):**
   - Task A cá»‘ Ä‘á»c Ä‘á»‹a chá»‰ user stack cá»§a Task B â†’ **Data Abort** â†’ fault â†’ UART: `"data abort at EL0"` + `"faulting task 0"`
   - Task A restart â†’ tiáº¿p tá»¥c PING/PONG bÃ¬nh thÆ°á»ng

2. **Sá»­a `Cargo.toml`:** thÃªm feature `test-isolation`

3. **Sá»­a `idle_entry` hoáº·c thÃªm hÃ m test riÃªng (gated):**
   - Trong láº§n cháº¡y Ä‘áº§u tiÃªn: cá»‘ Ä‘á»c `__user_stacks_start + 0x1000` (stack task 1)
   - Expected: Data Abort â†’ fault â†’ restart

**Checkpoint:** QEMU output hiá»‡n "data abort at EL0" cho task vi pháº¡m. Task khÃ¡c khÃ´ng áº£nh hÆ°á»Ÿng. Sau restart, há»‡ thá»‘ng tiáº¿p tá»¥c PING/PONG.

---

### H5 â€” Viáº¿t unit tests cho per-task address space

**Má»¥c tiÃªu:** ~10 test má»›i trong `tests/host_tests.rs`, nhÃ³m **AddressSpace**.

**Test cases:**

| # | Test name | MÃ´ táº£ |
|---|---|---|
| 1 | `addr_page_table_base_per_task` | `page_table_base(0) != page_table_base(1) != page_table_base(2)` |
| 2 | `addr_ttbr0_includes_asid` | `ttbr0_for_task(0, 1)` cÃ³ ASID=1 trong bits [63:48] |
| 3 | `addr_ttbr0_base_aligned_4k` | Base address 4KB-aligned (bits [11:0] = 0) |
| 4 | `addr_per_task_l3_user_stack_own` | Task 0 L3: own stack page = AP_RW_EL0 |
| 5 | `addr_per_task_l3_user_stack_other` | Task 0 L3: other stack pages = AP_RW_EL1 (not EL0) |
| 6 | `addr_per_task_l3_kernel_data_el1_only` | Kernel data pages váº«n AP_RW_EL1 trong per-task table |
| 7 | `addr_per_task_l3_shared_code` | `.text` pages váº«n AP_RO_EL0 (shared, executable) |
| 8 | `addr_kernel_table_user_stacks_el1` | Kernel boot table: user stacks = AP_RW_EL1 |
| 9 | `addr_tcb_ttbr0_survives_restart` | `restart_task()` khÃ´ng xÃ³a `ttbr0` |
| 10 | `addr_asid_unique_per_task` | ASID 1, 2, 3 cho 3 tasks |

**Cáº­p nháº­t `reset_test_state()`:** Reset `ttbr0` trong má»—i TCB vá» 0.

**Checkpoint:** `cargo test` â€” táº¥t cáº£ test cÅ© + má»›i pass (~79 tests: 69 cÅ© + 10 má»›i).

---

### H6 â€” Cáº­p nháº­t QEMU boot test + CI

**Má»¥c tiÃªu:** ThÃªm checkpoint má»›i vÃ o boot test scripts.

**Thay Ä‘á»•i:**

1. **Sá»­a `tests/qemu_boot_test.sh`:**
   - ThÃªm checkpoint: `"[AegisOS] per-task address spaces assigned"`

2. **Sá»­a `tests/qemu_boot_test.ps1`:**
   - TÆ°Æ¡ng tá»±

3. **CI tá»± Ä‘á»™ng pass** â€” `.github/workflows/ci.yml` khÃ´ng cáº§n sá»­a (dÃ¹ng script hiá»‡n cÃ³).

**Checkpoint:** CI green: host tests + QEMU boot all pass.

---

## TÃ³m táº¯t thay Ä‘á»•i theo file

| File | Thay Ä‘á»•i | Sub-phase |
|---|---|---|
| `linker.ld` | `.page_tables` 4Ã—4096 â†’ 13Ã—4096 | H1 |
| `src/mmu.rs` | Refactor `init()` build 13 tables, thÃªm `page_table_base()`, `ttbr0_for_task()` | H1 |
| `src/boot.s` | TTBR0 trá» kernel boot L1 (page 10) thay vÃ¬ page 0 | H1 |
| `src/sched.rs` | ThÃªm `ttbr0: u64` vÃ o Tcb, TTBR0 swap trong `schedule()` + `bootstrap()` | H2, H3 |
| `src/main.rs` | GÃ¡n `ttbr0` cho 3 tasks, thÃªm UART message | H2 |
| `Cargo.toml` | ThÃªm feature `test-isolation` | H4 |
| `src/main.rs` | Test isolation scenario (gated) | H4 |
| `tests/host_tests.rs` | ~10 test má»›i nhÃ³m AddressSpace | H5 |
| `tests/qemu_boot_test.sh` | ThÃªm checkpoint | H6 |
| `tests/qemu_boot_test.ps1` | ThÃªm checkpoint | H6 |

### KhÃ´ng thay Ä‘á»•i:
- `src/ipc.rs` â€” IPC dÃ¹ng register copy, khÃ´ng truy cáº­p user memory
- `src/cap.rs` â€” capability system giá»¯ nguyÃªn
- `src/gic.rs`, `src/timer.rs`, `src/uart.rs` â€” khÃ´ng liÃªn quan
- `src/exception.rs` â€” handler cháº¡y á»Ÿ EL1 vá»›i per-task TTBR0, váº«n OK (táº¥t cáº£ kernel regions cÃ³ AP_RW_EL1)

---

## SÆ¡ Ä‘á»“ page table sau Phase H

```
                    â”Œâ”€â”€â”€ L1_task0 (page 1) â”€â”€â”¬â”€â”€ [0] â†’ L2_device (page 0, SHARED)
                    â”‚                        â””â”€â”€ [1] â†’ L2_ram_task0 (page 4)
                    â”‚                                    â”œâ”€â”€ [0] â†’ L3_task0 (page 7)
                    â”‚                                    â”‚          â”œâ”€â”€ .text: AP_RO_EL0 âœ…
                    â”‚                                    â”‚          â”œâ”€â”€ .data: AP_RW_EL1
                    â”‚                                    â”‚          â”œâ”€â”€ user_stack_0: AP_RW_EL0 âœ…
Task 0 (TTBR0) â”€â”€â”€â”€â”˜                                    â”‚          â”œâ”€â”€ user_stack_1: AP_RW_EL1 ğŸ”’
                                                         â”‚          â””â”€â”€ user_stack_2: AP_RW_EL1 ğŸ”’
                                                         â””â”€â”€ [1..63] â†’ RAM 2MB blocks

                    â”Œâ”€â”€â”€ L1_task1 (page 2) â”€â”€â”¬â”€â”€ [0] â†’ L2_device (page 0, SHARED)
                    â”‚                        â””â”€â”€ [1] â†’ L2_ram_task1 (page 5)
                    â”‚                                    â”œâ”€â”€ [0] â†’ L3_task1 (page 8)
                    â”‚                                    â”‚          â”œâ”€â”€ .text: AP_RO_EL0 âœ…
                    â”‚                                    â”‚          â”œâ”€â”€ .data: AP_RW_EL1
                    â”‚                                    â”‚          â”œâ”€â”€ user_stack_0: AP_RW_EL1 ğŸ”’
Task 1 (TTBR0) â”€â”€â”€â”€â”˜                                    â”‚          â”œâ”€â”€ user_stack_1: AP_RW_EL0 âœ…
                                                         â”‚          â””â”€â”€ user_stack_2: AP_RW_EL1 ğŸ”’
                                                         â””â”€â”€ [1..63] â†’ RAM 2MB blocks

                    â”Œâ”€â”€â”€ L1_task2 (page 3) â”€â”€â”¬â”€â”€ [0] â†’ L2_device (page 0, SHARED)
                    â”‚                        â””â”€â”€ [1] â†’ L2_ram_task2 (page 6)
                    â”‚                                    â”œâ”€â”€ [0] â†’ L3_task2 (page 9)
                    â”‚                                    â”‚          â”œâ”€â”€ .text: AP_RO_EL0 âœ…
                    â”‚                                    â”‚          â”œâ”€â”€ .data: AP_RW_EL1
                    â”‚                                    â”‚          â”œâ”€â”€ user_stack_0: AP_RW_EL1 ğŸ”’
Task 2 (TTBR0) â”€â”€â”€â”€â”˜                                    â”‚          â”œâ”€â”€ user_stack_1: AP_RW_EL1 ğŸ”’
                                                         â”‚          â””â”€â”€ user_stack_2: AP_RW_EL0 âœ…
                                                         â””â”€â”€ [1..63] â†’ RAM 2MB blocks

Kernel boot (pages 10-12): táº¥t cáº£ user stacks = AP_RW_EL1 (khÃ´ng EL0 nÃ o truy cáº­p)
```

---

## Äiá»ƒm cáº§n lÆ°u Ã½

1. **Page tables pháº£i náº±m trong `.page_tables` section.** Linker Ä‘áº·t á»Ÿ vÃ¹ng data â†’ AP_RW_EL1, XN. `mmu::init()` ghi trá»±c tiáº¿p qua `write_volatile`. Má»Ÿ rá»™ng section khÃ´ng áº£nh hÆ°á»Ÿng alignment.

2. **TCB size tÄƒng 8 byte** (`ttbr0: u64`). Offset cÃ¡c field cÅ© khÃ´ng Ä‘á»•i (repr(C), thÃªm cuá»‘i).

3. **ASID 8-bit vs 16-bit.** TCR_EL1 hiá»‡n táº¡i AS bit (bit 36) = 0 â†’ 8-bit ASID â†’ há»— trá»£ 256 ASID. 3 tasks chá»‰ cáº§n 3 ASID â†’ dÆ° sá»©c.

4. **`isb` sau `msr ttbr0_el1`** lÃ  Ä‘á»§ khi dÃ¹ng ASID. KhÃ´ng cáº§n `tlbi` vÃ¬ ASID tag TLB entries â€” entries cÅ© tá»± nhiÃªn khÃ´ng match ASID má»›i.

5. **Boot sequence:** boot.s init MMU vá»›i kernel boot table â†’ kernel_main() build per-task tables â†’ gÃ¡n ttbr0 cho TCBs â†’ bootstrap() swap sang task 0 TTBR0 â†’ eret.

6. **Exception handler TTBR0:** Khi IRQ á»Ÿ EL0, TTBR0 váº«n lÃ  cá»§a task Ä‘ang cháº¡y. Handler á»Ÿ EL1 â†’ dÃ¹ng AP_RW_EL1 entries â†’ truy cáº­p má»i kernel memory OK. Khi schedule() chá»n task má»›i â†’ swap TTBR0 trÆ°á»›c eret. **KhÃ´ng cáº§n swap TTBR0 khi vÃ o handler.**

7. **restart_task() áº£nh hÆ°á»Ÿng:** Giá»¯ nguyÃªn `ttbr0` â€” task restart dÃ¹ng cÃ¹ng address space. HÃ m `restart_task` zero-out context + set entry/stack â†’ user stack physical address khÃ´ng Ä‘á»•i â†’ mapping váº«n Ä‘Ãºng.

8. **Bá»™ nhá»› thÃªm:** 9 pages Ã— 4KB = **36 KiB BSS**. Tá»•ng page tables: 52 KiB. Váº«n ráº¥t nhá» cho bare-metal.

9. **DO-178C mapping:**
   - Per-task address space = Â§5.3.1 (Memory Partitioning)
   - TTBR0 swap = Â§5.3.3 (Detailed Design â€” address space isolation)
   - Isolation test = Â§6.4.3 (Integration Testing â€” interference freedom)
   - ISO 26262 Part 6 Â§7.4.6 â€” Freedom from interference between software partitions

---

## Tá»•ng káº¿t chi phÃ­

| Metric | GiÃ¡ trá»‹ |
|--------|---------|
| File má»›i | 0 |
| File sá»­a | 7 (`linker.ld`, `mmu.rs`, `boot.s`, `sched.rs`, `main.rs`, `host_tests.rs`, boot test scripts) |
| DÃ²ng code thÃªm | ~120 dÃ²ng kernel + ~100 dÃ²ng test |
| Bá»™ nhá»› thÃªm | 36 KiB BSS (9 Ã— 4KB page tables) |
| Tests má»›i | ~10 |
| Tá»•ng tests sau Phase H | ~79 (69 cÅ© + 10 má»›i) |
| Risk | **Trung bÃ¬nh** â€” swap TTBR0 lÃ  thao tÃ¡c nháº¡y cáº£m, sai = crash. NhÆ°ng logic Ä‘Æ¡n giáº£n (chá»‰ thay 3 user stack entries), test coverage cao. |

---

## Äá» xuáº¥t hÃ nh Ä‘á»™ng tiáº¿p theo

1. **Báº¯t Ä‘áº§u H1** â€” Má»Ÿ rá»™ng `.page_tables` trong `linker.ld` lÃªn 13 pages. Refactor `mmu::init()` build per-task tables. Sá»­a `boot.s` trá» kernel boot L1. Verify QEMU boot bÃ¬nh thÆ°á»ng.

2. **Tiáº¿p H2** â€” ThÃªm `ttbr0: u64` vÃ o Tcb. GÃ¡n `ttbr0` cho 3 tasks trong `kernel_main()`. Verify build + test cÅ© pass.

3. **H3 (critical)** â€” Swap TTBR0 trong `schedule()` + `bootstrap()`. Verify QEMU boot PING/PONG bÃ¬nh thÆ°á»ng. **ÄÃ¢y lÃ  bÆ°á»›c rá»§i ro cao nháº¥t â€” test ká»¹ trÃªn QEMU.**

4. **H4** â€” Test isolation: task cá»‘ Ä‘á»c stack task khÃ¡c â†’ Data Abort â†’ chá»©ng minh cÃ¡ch ly hoáº¡t Ä‘á»™ng.

5. **H5** â€” Viáº¿t 10 unit tests. Verify ~79 tests pass.

6. **H6** â€” Cáº­p nháº­t boot test scripts + verify CI green.

7. **Sau H6** â€” Viáº¿t blog #08 ("Má»—i nhÃ  cÃ³ hÃ ng rÃ o riÃªng â€” Per-Task Address Space"). LÃªn káº¿ hoáº¡ch Phase I (vÃ­ dá»¥: Dynamic Memory Grant, Capability Delegation, hoáº·c Kernel Hardening).
